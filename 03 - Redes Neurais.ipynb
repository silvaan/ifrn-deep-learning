{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ceedf7",
   "metadata": {},
   "source": [
    "# Redes Neurais\n",
    "\n",
    "Nesta seção vamos treinar uma rede neural simples, implementada com PyTorch, para classificar pontos em 2D de um dataset sintético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d388e647",
   "metadata": {},
   "source": [
    "## Datasets e DataLoaders\n",
    "\n",
    "Para treinar um modelo, precisamos de um pipeline de dados eficiente. O PyTorch oferece duas primitivas de dados fundamentais para isso: `torch.utils.data.Dataset` e `torch.utils.data.DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dataset sintético (moon dataset)\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=seed)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d1b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"coolwarm\", edgecolor=None, s=25)\n",
    "plt.title(\"Dataset Sintético: Two Moons\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469dab3",
   "metadata": {},
   "source": [
    "### O Dataset\n",
    "\n",
    "A classe `Dataset` é uma classe abstrata que representa uma fonte de dados. Para criar seu próprio dataset, você precisa herdar desta classe e sobrescrever três métodos especiais (métodos mágicos):\n",
    "\n",
    "1.  `__init__(self, ...)`: O construtor da classe. É executado uma única vez ao instanciar o dataset. É aqui que você normalmente faria o carregamento inicial dos dados (ex: ler um arquivo CSV, encontrar os caminhos das imagens em um diretório).\n",
    "\n",
    "2.  `__len__(self)`: Este método deve retornar o número total de amostras no seu dataset. O `DataLoader` utiliza essa informação para saber o tamanho do dataset e definir os índices.\n",
    "\n",
    "3.  `__getitem__(self, idx)`: Este método é responsável por carregar e retornar **uma única amostra** do dataset, dado um índice `idx`. É aqui que transformações nos dados (como data augmentation ou normalização) são frequentemente aplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonsDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)\n",
    "        self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb498a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = MoonsDataset(X, y)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(seed)\n",
    ")\n",
    "\n",
    "print(f\"Tamanho treino: {len(train_dataset)}, validação: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4027d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_dataset[0]\n",
    "X.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b384d0a",
   "metadata": {},
   "source": [
    "### O Data Loader\n",
    "\n",
    "Uma vez que temos um objeto `Dataset`, que sabe como acessar amostras individuais, precisamos de uma forma eficiente de iterar sobre ele durante o treinamento. É aqui que entra o `DataLoader`.\n",
    "\n",
    "O `DataLoader` é um iterador que envolve um `Dataset` e automatiza o processo de criação de mini-lotes (*mini-batches*). Suas principais funcionalidades são:\n",
    "\n",
    "-   **Agrupamento em Lotes (Batching)**: Agrupa múltiplas amostras retornadas pelo `__getitem__` do `Dataset` para formar um lote (batch) de dados.\n",
    "-   **Embaralhamento (Shuffling)**: Permite embaralhar os dados a cada época (`shuffle=True`) para evitar que o modelo aprenda a ordem dos dados e melhore a generalização.\n",
    "-   **Carregamento Paralelo (Parallel Loading)**: Pode usar múltiplos subprocessos (`num_workers`) para carregar os dados em paralelo, evitando que o carregamento de dados se torne um gargalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a5507",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea750900",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca8e19f",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Vamos definir uma rede neural totalmente conectada simples (MLP) para classificar os pontos 2D em duas classes.\n",
    "\n",
    "- Entrada: vetor 2D (coordenadas do ponto).\n",
    "- Camadas escondidas: algumas camadas lineares com não-linearidade ReLU.\n",
    "- Saída: logits para 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804186f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=16, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b7bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eecc5c",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "No treinamento vamos:\n",
    "\n",
    "- Iterar por várias épocas.\n",
    "- Para cada época:\n",
    "  - Colocar o modelo em modo de treino (`model.train()`).\n",
    "  - Percorrer o `train_loader`, calculando *loss* e atualizando os pesos com `optimizer.step()`.\n",
    "  - Ao final da época, avaliar no conjunto de validação para obter *loss* e acurácia de validação.\n",
    "- Armazenar o histórico de *loss* e acurácia de treino/validação, e ao final plotar as curvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3bf036",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "history = {k: [] for k in [\"train_loss\",\"val_loss\",\"train_acc\",\"val_acc\"]}\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "    # ---------- Treino ----------\n",
    "    model.train()\n",
    "    train_losses, train_accs = [], []\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        preds = logits.argmax(1)\n",
    "        acc = (preds == yb).float().mean().item()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    train_loss = np.mean(train_losses)\n",
    "    train_acc = np.mean(train_accs)\n",
    "\n",
    "    # ---------- Validação ----------\n",
    "    model.eval()\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "            preds = logits.argmax(1)\n",
    "            acc = (preds == yb).float().mean().item()\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_accs.append(acc)\n",
    "\n",
    "    val_loss = np.mean(val_losses)\n",
    "    val_acc = np.mean(val_accs)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    if epoch % 3 == 0 or epoch == 1:\n",
    "        print(f\"{epoch:03d} | loss {train_loss:.4f}/{val_loss:.4f}  acc {train_acc:.3f}/{val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8efb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"Treino\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"Validação\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Curva de Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plotar curvas de acurácia\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, history[\"train_acc\"], label=\"Treino\")\n",
    "plt.plot(epochs, history[\"val_acc\"], label=\"Validação\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.title(\"Curva de Acurácia\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ea473",
   "metadata": {},
   "source": [
    "# Validação\n",
    "\n",
    "Aqui calculamos explicitamente a acurácia final no conjunto de validação utilizando o modelo treinado. Essa etapa é semelhante ao que fizemos ao longo do treinamento, mas executada apenas uma vez ao final, como resumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "val_accuracy_final = correct / total\n",
    "print(f\"Acurácia final na validação: {val_accuracy_final:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, device):\n",
    "    model.eval()\n",
    "    X_np = X if isinstance(X, np.ndarray) else X.numpy()\n",
    "    y_np = y if isinstance(y, np.ndarray) else y.numpy()\n",
    "\n",
    "    x_min, x_max = X_np[:, 0].min() - 0.5, X_np[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_np[:, 1].min() - 0.5, X_np[:, 1].max() + 0.5\n",
    "\n",
    "    # Grade de pontos\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, 200),\n",
    "        np.linspace(y_min, y_max, 200)\n",
    "    )\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()].astype(np.float32)\n",
    "    grid_t = torch.from_numpy(grid).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(grid_t)\n",
    "        probs = F.softmax(logits, dim=1)[:, 1]  # prob da classe 1\n",
    "        Z = probs.cpu().numpy().reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    # Contorno preenchido com as probabilidades\n",
    "    cs = plt.contourf(xx, yy, Z, levels=50, alpha=0.8, cmap=\"RdBu\")\n",
    "    plt.colorbar(cs, label=\"Probabilidade da classe 1\")\n",
    "\n",
    "    # Pontos reais\n",
    "    plt.scatter(X_np[:, 0], X_np[:, 1], c=y_np, cmap=\"viridis\", edgecolor=\"k\", s=20)\n",
    "    plt.title(\"Fronteira de decisão da rede neural\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.show()\n",
    "\n",
    "# Plotar fronteira usando todo o dataset\n",
    "plot_decision_boundary(model, X, y, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eacc95e",
   "metadata": {},
   "source": [
    "## Inferência\n",
    "\n",
    "Na inferência usamos o modelo treinado para prever a classe de novos pontos 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e844002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de inferência em alguns pontos novos\n",
    "novos_pontos = np.array([\n",
    "    [-1.0, 0.5],\n",
    "    [2.0, -0.5],\n",
    "    [0.0, 1.0],\n",
    "    [1.5, 0.0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "novos_pontos_t = torch.from_numpy(novos_pontos).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(novos_pontos_t)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    preds = probs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "for p, c in zip(novos_pontos, preds):\n",
    "    print(f\"Ponto {p} -> classe prevista: {c}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
