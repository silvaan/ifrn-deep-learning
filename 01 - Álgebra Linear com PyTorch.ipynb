{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d21c59",
   "metadata": {},
   "source": [
    "# Fundamentos de Álgebra Linear com PyTorch\n",
    "\n",
    "Este notebook serve como uma introdução aos conceitos fundamentais da Álgebra Linear, a matemática dos dados. A compreensão profunda destes conceitos é um pré-requisito para o estudo avançado de qualquer campo da Inteligência Artificial.\n",
    "\n",
    "## PyTorch\n",
    "\n",
    "O PyTorch é uma das bibliotecas mais utilizadas em Deep Learning. Ele fornece uma forma eficiente e intuitiva de lidar com **tensores**, estruturas que generalizam vetores e matrizes para dimensões arbitrárias. Assim como o NumPy trabalha com arrays, o PyTorch trabalha com tensores otimizados para execução em GPU, permitindo alto desempenho em cálculos matriciais e operações de aprendizado profundo.\n",
    "\n",
    "## Tensores\n",
    "\n",
    "Um tensor é a unidade básica do PyTorch. Ele pode representar um número (escalar), um vetor, uma matriz, ou dados de múltiplas dimensões, como imagens e vídeos. Tensores são fundamentais porque quase todas as operações em aprendizado de máquina envolvem manipulações de estruturas numéricas desse tipo.\n",
    "\n",
    "Além disso, o PyTorch permite mover tensores entre CPU e GPU com facilidade, o que é essencial para treinar redes neurais em larga escala."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f5fa49",
   "metadata": {},
   "source": [
    "## 1. Escalares, Vetores, Matrizes e Tensores\n",
    "\n",
    "A Álgebra Linear lida fundamentalmente com vetores. No entanto, é útil começar com as estruturas que os englobam.\n",
    "\n",
    "-   **Escalar**: Um único número, como $x \\in \\mathbb{R}$.\n",
    "-   **Vetor**: Um array de números ordenados. Um vetor $v \\in \\mathbb{R}^n$ possui $n$ componentes, $v = [v_1, v_2, ..., v_n]$. Geralmente, nos referimos a ele como um vetor coluna:\n",
    "$$ v = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{bmatrix} $$\n",
    "-   **Matriz**: Um array bidimensional de números. Uma matriz $A \\in \\mathbb{R}^{m \\times n}$ tem $m$ linhas e $n$ colunas.\n",
    "$$ A = \\begin{bmatrix}\n",
    "A_{1,1} & A_{1,2} & \\cdots & A_{1,n} \\\\\n",
    "A_{2,1} & A_{2,2} & \\cdots & A_{2,n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "A_{m,1} & A_{m,2} & \\cdots & A_{m,n}\n",
    "\\end{bmatrix} $$\n",
    "-   **Tensor**: É uma generalização de um escalar (tensor de ordem 0), um vetor (tensor de ordem 1) e uma matriz (tensor de ordem 2) para um número arbitrário de dimensões (ordem $d$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e74c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Verificando a versão do PyTorch\n",
    "print(f\"Versão do PyTorch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar (Tensor de ordem 0)\n",
    "escalar = torch.tensor(3.14)\n",
    "\n",
    "print(\"Escalar:\")\n",
    "print(escalar)\n",
    "print(\"Ordem (ndim):\", escalar.ndim)\n",
    "print(\"Shape:\", escalar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d00a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetor (Tensor de ordem 1)\n",
    "vetor = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(\"Vetor:\")\n",
    "print(vetor)\n",
    "print(\"Ordem (ndim):\", vetor.ndim)\n",
    "print(\"Shape:\", vetor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz (Tensor de ordem 2)\n",
    "matriz = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "print(\"Matriz:\")\n",
    "print(matriz)\n",
    "print(\"Ordem (ndim):\", matriz.ndim)\n",
    "print(\"Shape:\", matriz.shape) # 3 linhas, 2 colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf29e01",
   "metadata": {},
   "source": [
    "## 2. Criação e Manipulação de Tensores em PyTorch\n",
    "\n",
    "Embora possamos criar tensores a partir de listas Python, PyTorch oferece funções otimizadas para criar tensores comumente utilizados e para manipular seu formato.\n",
    "\n",
    "### Funções de Criação\n",
    "- `torch.ones(shape)`: Cria um tensor preenchido com o valor 1.\n",
    "- `torch.zeros(shape)`: Cria um tensor preenchido com o valor 0.\n",
    "- `torch.rand(shape)`: Cria um tensor com valores aleatórios de uma distribuição uniforme em $[0, 1)$.\n",
    "- `torch.randn(shape)`: Cria um tensor com valores aleatórios de uma distribuição normal padrão (média 0, variância 1).\n",
    "- `torch.arange(start, end, step)`: Cria um tensor com valores em um intervalo.\n",
    "- `torch.linspace(start, end, steps)`: Cria um tensor com um número específico de valores (`steps`) espaçados linearmente entre `start` e `end`.\n",
    "\n",
    "### Manipulação de Formato\n",
    "- `.shape`: Atributo que retorna a dimensionalidade do tensor.\n",
    "- `.reshape(new_shape)` / `.view(new_shape)`: Remodelam o tensor para um novo formato. `view` é mais rápido, mas só funciona em tensores contíguos na memória. `reshape` é mais flexível.\n",
    "- `.flatten()`: Transforma um tensor multidimensional em um tensor 1D (um vetor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff88907",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(2, 3)\n",
    "print(\"Tensor de Zeros (2, 3):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f58583",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(3, 2)\n",
    "print(\"Tensor de Uns (3, 2):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 5)\n",
    "print(\"Tensor com arange(0, 5):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c111843",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0, 1, 5)\n",
    "print(\"Tensor com linspace(0, 1, 5 passos):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e51764",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 2)\n",
    "print(\"Tensor Rand (dist. uniforme):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 2)\n",
    "print(\"Tensor Randn (dist. normal):\\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0da97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulação de formato\n",
    "x = torch.arange(12)\n",
    "print(\"--- Manipulação de Formato ---\")\n",
    "print(\"\\nTensor original (x):\\n\", x)\n",
    "print(\"Shape de x:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89456b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape\n",
    "x_reshaped = x.reshape(3, 4)\n",
    "print(\"x com reshape(3, 4):\\n\", x_reshaped)\n",
    "print(\"Shape de x_reshaped:\", x_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e84c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten\n",
    "x_flattened = x_reshaped.flatten()\n",
    "print(\"x_reshaped achatado (flatten):\\n\", x_flattened)\n",
    "print(\"Shape de x_flattened:\", x_flattened.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82081987",
   "metadata": {},
   "source": [
    "## 3. Indexação e Fatiamento\n",
    "\n",
    "Acessar e modificar subconjuntos de um tensor é uma operação rotineira. A sintaxe em PyTorch é similar à do NumPy, utilizando colchetes `[]` e o operador de fatiamento `:` (dois pontos). A indexação começa em zero.\n",
    "\n",
    "-   Acessar um elemento: `T[i, j]` para o elemento na linha `i` e coluna `j`.\n",
    "-   Acessar uma linha: `T[i, :]` para a linha `i` inteira.\n",
    "-   Acessar uma coluna: `T[:, j]` para a coluna `j` inteira.\n",
    "-   Acessar um subconjunto: `T[start_row:end_row, start_col:end_col]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7667f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um tensor 2D para os exemplos\n",
    "T = torch.arange(20).reshape(5, 4)\n",
    "\n",
    "print(\"Tensor original (5x4):\\n\", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c3224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando a linha de índice 1\n",
    "T_linha_1 = T[1, :]\n",
    "\n",
    "print(\"Linha de índice 1 (T[1, :]):\\n\", T_linha_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando a coluna de índice 2\n",
    "T_coluna_2 = T[:, 2]\n",
    "\n",
    "print(\"Coluna de índice 2 (T[:, 2]):\\n\", T_coluna_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606324ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessando o elemento na linha 3, coluna 1\n",
    "T_el = T[3, 1]\n",
    "\n",
    "print(\"Elemento em (3, 1):\", T_el.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e58c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fatiando para obter um sub-bloco (linhas 1 e 2, colunas 0 e 1)\n",
    "sub_bloco = T[1:3, 0:2]\n",
    "\n",
    "print(\"Sub-bloco T[1:3, 0:2]:\\n\", sub_bloco)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd3147",
   "metadata": {},
   "source": [
    "## 4. Redução de Tensores\n",
    "\n",
    "Operações de redução agregam todos os valores de um tensor (ou de uma de suas dimensões) em um único valor, como soma, média, produto, etc.\n",
    "\n",
    "- `torch.sum()`: Soma dos elementos.\n",
    "- `torch.mean()`: Média dos elementos.\n",
    "- `torch.prod()`: Produto dos elementos.\n",
    "- `torch.max()` / `torch.min()`: Valores máximo e mínimo.\n",
    "\n",
    "O argumento `dim` especifica a dimensão ao longo da qual a operação é aplicada.\n",
    "- `dim=0`: Reduz ao longo das linhas (resultando em um valor por coluna).\n",
    "- `dim=1`: Reduz ao longo das colunas (resultando em um valor por linha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5275a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torch.arange(1, 7, dtype=torch.float32).reshape(2, 3)\n",
    "print(\"Tensor original:\\n\", T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07829ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redução total\n",
    "T_soma = T.sum()\n",
    "T_media = T.mean()\n",
    "\n",
    "print(\"Soma total (sum):\", T_soma.item())\n",
    "print(\"Média total (mean):\", T_media.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redução por dimensão\n",
    "soma_colunas = T.sum(dim=0)\n",
    "print(\"Soma ao longo das linhas (dim=0):\", soma_colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05472cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma_linhas = T.sum(dim=1)\n",
    "print(\"Soma ao longo das colunas (dim=1):\", soma_linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vals, max_indices = T.max(dim=1)\n",
    "print(\"\\nValores máximos por linha (dim=1):\", max_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ead54",
   "metadata": {},
   "source": [
    "## 5. Operações com Vetores\n",
    "\n",
    "As operações mais básicas em Álgebra Linear são a adição de vetores e a multiplicação por escalar.\n",
    "\n",
    "### Adição de Vetores\n",
    "A soma de dois vetores $u, v \\in \\mathbb{R}^n$ é realizada elemento a elemento:\n",
    "$$ w = u + v \\quad \\text{onde} \\quad w_i = u_i + v_i $$\n",
    "\n",
    "### Multiplicação por Escalar\n",
    "A multiplicação de um vetor $v \\in \\mathbb{R}^n$ por um escalar $c \\in \\mathbb{R}$ resulta em um novo vetor onde cada elemento é multiplicado por $c$:\n",
    "$$ w = c v \\quad \\text{onde} \\quad w_i = c \\cdot v_i $$\n",
    "Geometricamente, isso \"escala\" (estica ou encolhe) o vetor $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bfdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adição de Vetores\n",
    "u = torch.tensor([1, 2, 3])\n",
    "v = torch.tensor([10, 20, 30])\n",
    "soma_vetores = u + v\n",
    "\n",
    "print(\"Adição de Vetores (u + v):\")\n",
    "print(soma_vetores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiplicação por Escalar\n",
    "c = 2\n",
    "w = c * u\n",
    "\n",
    "print(f\"Multiplicação por Escalar ({c} * u):\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfa975",
   "metadata": {},
   "source": [
    "## 6. Norma de um Vetor\n",
    "\n",
    "A norma de um vetor é uma medida do seu \"comprimento\" ou \"magnitude\". A norma mais comum é a norma Euclidiana, ou norma $\\ell_2$. Para um vetor $v \\in \\mathbb{R}^n$, a norma $\\ell_2$, denotada por $||v||_2$, é calculada como:\n",
    "\n",
    "$$ ||v||_2 = \\sqrt{\\sum_{i=1}^{n} v_i^2} = \\sqrt{v_1^2 + v_2^2 + \\cdots + v_n^2} $$\n",
    "\n",
    "A norma de um vetor é sempre um valor não-negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f97b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([3.0, 4.0])\n",
    "\n",
    "# Calculando a norma l2\n",
    "# sqrt(3^2 + 4^2) = sqrt(9 + 16) = sqrt(25) = 5\n",
    "norma_v = torch.linalg.norm(v)\n",
    "\n",
    "print(\"Vetor v:\", v)\n",
    "print(\"Norma l2 de v:\", norma_v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetor unitário: um vetor com norma igual a 1\n",
    "# Para obter um vetor unitário, dividimos o vetor pela sua norma\n",
    "v_unitario = v / norma_v\n",
    "\n",
    "print(\"Vetor unitário de v:\", v_unitario)\n",
    "print(\"Norma do vetor unitário:\", torch.linalg.norm(v_unitario).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0797715",
   "metadata": {},
   "source": [
    "## 7. Produto Interno e Ângulo entre Vetores\n",
    "\n",
    "O produto interno (ou produto escalar, *dot product*) de dois vetores $u, v \\in \\mathbb{R}^n$ é a soma dos produtos dos elementos correspondentes:\n",
    "\n",
    "$$ u^T v = u \\cdot v = \\sum_{i=1}^{n} u_i v_i $$\n",
    "\n",
    "Ele possui uma propriedade geométrica fundamental que o relaciona ao ângulo $\\theta$ entre os vetores:\n",
    "\n",
    "$$ u \\cdot v = ||u||_2 \\ ||v||_2 \\ \\cos(\\theta) $$\n",
    "\n",
    "Podemos usar esta relação para encontrar o ângulo entre os vetores. Rearranjando a equação, temos:\n",
    "\n",
    "$$ \\cos(\\theta) = \\frac{u \\cdot v}{||u||_2 \\ ||v||_2} $$\n",
    "\n",
    "E, finalmente, o ângulo $\\theta$ é obtido pela função arco cosseno:\n",
    "\n",
    "$$ \\theta = \\arccos\\left(\\frac{u \\cdot v}{||u||_2 \\ ||v||_2}\\right) $$\n",
    "\n",
    "Um produto interno de zero indica que os vetores são ortogonais ($\\theta=90^\\circ$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad407b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([1, 2, 3])\n",
    "v = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Calculando o produto interno\n",
    "# 1*4 + 2*5 + 3*6 = 4 + 10 + 18 = 32\n",
    "produto_interno = torch.dot(u, v)\n",
    "\n",
    "print(\"Vetor u:\", u)\n",
    "print(\"Vetor v:\", v)\n",
    "print(\"Produto Interno (u . v):\", produto_interno.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0170f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([1., 2.])\n",
    "v = torch.tensor([3., 1.])\n",
    "\n",
    "# 1. Calcular o produto interno\n",
    "produto_interno = torch.dot(u, v)\n",
    "\n",
    "# 2. Calcular a norma de cada vetor\n",
    "norma_u = torch.linalg.norm(u)\n",
    "norma_v = torch.linalg.norm(v)\n",
    "\n",
    "# 3. Calcular o cosseno do ângulo\n",
    "cos_theta = produto_interno / (norma_u * norma_v)\n",
    "\n",
    "# 4. Calcular o ângulo em radianos usando arccos\n",
    "theta_rad = torch.acos(cos_theta)\n",
    "\n",
    "# Converter para graus\n",
    "theta_deg = theta_rad * 180.0 / torch.pi\n",
    "\n",
    "print(f\"Cosseno do ângulo: {cos_theta.item():.2f}\")\n",
    "print(f\"Ângulo em radianos: {theta_rad.item():.2f}\")\n",
    "print(f\"Ângulo em graus: {theta_deg:.2f}°\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de vetores ortogonais\n",
    "u_ort = torch.tensor([1., 0.])\n",
    "v_ort = torch.tensor([0., 1.])\n",
    "\n",
    "print(\"Produto Interno de vetores ortogonais:\", torch.dot(u_ort, v_ort).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d50af",
   "metadata": {},
   "source": [
    "## 8. Multiplicação de Matriz por Vetor\n",
    "\n",
    "A multiplicação de uma matriz $A \\in \\mathbb{R}^{m \\times n}$ por um vetor $v \\in \\mathbb{R}^n$ resulta em um novo vetor $b \\in \\mathbb{R}^m$. Essa operação representa uma **transformação linear**.\n",
    "\n",
    "Pense na matriz $A$ como uma função que \"transforma\" o vetor $v$, que vive no espaço $\\mathbb{R}^n$ (o espaço de entrada), e o mapeia para um novo vetor $b=Av$, que vive no espaço $\\mathbb{R}^m$ (o espaço de saída). Essa transformação pode rotacionar, escalar ou cisalhar (shear) o vetor original.\n",
    "\n",
    "O mecanismo desta transformação é que o vetor resultante $b$ é uma **combinação linear das colunas da matriz $A$**, onde os pesos dessa combinação são exatamente os **elementos do vetor $v$**:\n",
    "\n",
    "$$ b = A v = v_1 \\begin{bmatrix} A_{1,1} \\\\ \\vdots \\\\ A_{m,1} \\end{bmatrix} + v_2 \\begin{bmatrix} A_{1,2} \\\\ \\vdots \\\\ A_{m,2} \\end{bmatrix} + \\cdots + v_n \\begin{bmatrix} A_{1,n} \\\\ \\vdots \\\\ A_{m,n} \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07411943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de transformação A (leva de R^2 para R^3)\n",
    "A = torch.tensor([[1, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 1]], dtype=torch.float32)\n",
    "\n",
    "# Vetor original no espaço R^2\n",
    "v = torch.tensor([2., 3.])\n",
    "\n",
    "# Aplicar a transformação: A @ v\n",
    "# O resultado será um novo vetor no espaço R^3\n",
    "b = A @ v\n",
    "\n",
    "print(\"Matriz de Transformação A (leva de R^2 para R^3):\\n\", A)\n",
    "print(\"\\nVetor original v (em R^2):\\n\", v)\n",
    "print(\"\\nVetor transformado b = A@v (em R^3):\\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88869a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a intuição da combinação linear:\n",
    "# b = 2 * A[:,0] + 3 * A[:,1]\n",
    "b_combinacao_linear = v[0] * A[:, 0] + v[1] * A[:, 1]\n",
    "\n",
    "print(\"Resultado via combinação linear das colunas:\\n\", b_combinacao_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f829b5c",
   "metadata": {},
   "source": [
    "## 9. Multiplicação de Matrizes: Composição de Transformações\n",
    "\n",
    "Seguindo a mesma lógica, a multiplicação de duas matrizes, $C = AB$, representa a **composição de duas transformações lineares**.\n",
    "\n",
    "Se uma matriz $B \\in \\mathbb{R}^{n \\times p}$ transforma um vetor do espaço $\\mathbb{R}^p$ para $\\mathbb{R}^n$, e uma matriz $A \\in \\mathbb{R}^{m \\times n}$ transforma um vetor de $\\mathbb{R}^n$ para $\\mathbb{R}^m$, então a matriz produto $C \\in \\mathbb{R}^{m \\times p}$ representa a transformação única que leva diretamente do espaço $\\mathbb{R}^p$ para $\\mathbb{R}^m$.\n",
    "\n",
    "Em outras palavras, aplicar a transformação $C$ a um vetor $v$ é o mesmo que aplicar primeiro a transformação $B$ e depois aplicar a transformação $A$ ao resultado:\n",
    "\n",
    "$$ C v = (A B) v = A (B v) $$\n",
    "\n",
    "Cada elemento $C_{ij}$ da matriz resultante é o produto interno da $i$-ésima linha da matriz $A$ com a $j$-ésima coluna da matriz $B$.\n",
    "\n",
    "$$ C_{ij} = \\sum_{k=1}^{n} A_{ik} B_{kj} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d60eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([[1, 2], [3, 4]]) # Matriz 2x2\n",
    "B = torch.tensor([[10, 20], [30, 40]]) # Matriz 2x2\n",
    "\n",
    "# Usando torch.matmul ou o operador @\n",
    "C = torch.matmul(A, B)\n",
    "# C = A @ B\n",
    "\n",
    "print(\"Matriz A:\\n\", A)\n",
    "print(\"\\nMatriz B:\\n\", B)\n",
    "print(\"\\nResultado da multiplicação A @ B:\\n\", C)\n",
    "\n",
    "# Verificando a não-comutatividade\n",
    "print(\"\\nResultado da multiplicação B @ A:\\n\", B @ A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e74b5",
   "metadata": {},
   "source": [
    "## 10. Distância entre Vetores\n",
    "\n",
    "A distância entre dois pontos (representados por vetores) no espaço Euclidiano é o comprimento do vetor que conecta esses dois pontos. A distância Euclidiana entre dois vetores $u, v \\in \\mathbb{R}^n$ é definida como a norma do vetor diferença $u-v$:\n",
    "\n",
    "$$ \\text{dist}(u, v) = ||u - v||_2 = \\sqrt{\\sum_{i=1}^{n} (u_i - v_i)^2} $$\n",
    "\n",
    "Este conceito é a base para muitos algoritmos de Machine Learning, como o k-Nearest Neighbors (k-NN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80903f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([1., 5.])\n",
    "v = torch.tensor([4., 1.])\n",
    "\n",
    "# Calculando o vetor diferença\n",
    "diferenca = u - v\n",
    "\n",
    "# Calculando a norma do vetor diferença\n",
    "distancia = torch.linalg.norm(diferenca)\n",
    "# sqrt((1-4)^2 + (5-1)^2) = sqrt((-3)^2 + 4^2) = sqrt(9 + 16) = sqrt(25) = 5\n",
    "\n",
    "print(\"Vetor u:\", u)\n",
    "print(\"Vetor v:\", v)\n",
    "print(\"Distância Euclidiana entre u e v:\", distancia.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch também tem uma função de conveniência para isso\n",
    "distancia_pdist = torch.cdist(u.unsqueeze(0), v.unsqueeze(0))\n",
    "print(\"Distância calculada com torch.cdist:\", distancia_pdist.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b040d286",
   "metadata": {},
   "source": [
    "## 11. Broadcasting: Operações Inteligentes entre Tensores\n",
    "\n",
    "Em muitas situações, desejamos realizar operações entre tensores que não possuem exatamente o mesmo formato. O caso mais simples é operar um escalar com um tensor (e.g., somar o número 5 a todos os elementos de uma matriz). Uma abordagem mais complexa seria somar um vetor a cada linha de uma matriz.\n",
    "\n",
    "Broadcasting é um mecanismo poderoso e eficiente que realiza essas operações sem a necessidade de criar cópias dos dados na memória. Ele define um conjunto de regras para tratar tensores de formatos diferentes. A operação é possível se, ao comparar os formatos dos tensores da direita para a esquerda (a partir da última dimensão), uma das duas condições for verdadeira para cada par de dimensões:\n",
    "\n",
    "1.  As dimensões são iguais.\n",
    "2.  Uma das dimensões é 1 (um escalar é tratado como se tivesse dimensões de tamanho 1).\n",
    "\n",
    "Se essas condições forem satisfeitas, o tensor com a dimensão menor é virtualmente \"esticado\" (broadcasted) para corresponder ao tamanho da dimensão do outro tensor.\n",
    "\n",
    "**Exemplo:** Somar um vetor de formato `(3,)` a uma matriz de formato `(2, 3)`.\n",
    "\n",
    "1.  Alinhamos os formatos pela direita:\n",
    "    - Matriz: `2, 3`\n",
    "    - Vetor: `   3`\n",
    "2.  Comparando a última dimensão: `3` e `3`. Elas são iguais. (OK)\n",
    "3.  Comparando a penúltima dimensão: `2` e (não existe). O PyTorch adiciona uma dimensão de tamanho 1 ao vetor:\n",
    "    - Matriz: `2, 3`\n",
    "    - Vetor:  `1, 3`\n",
    "4.  Agora, comparamos a primeira dimensão: `2` e `1`. Como uma delas é `1`, a condição é satisfeita. (OK)\n",
    "\n",
    "O vetor de formato `(1, 3)` é então \"esticado\" para o formato `(2, 3)` e a soma é realizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 0: Somando um escalar a um tensor (caso mais simples)\n",
    "matriz_base = torch.arange(6).reshape(2, 3)\n",
    "escalar = 100\n",
    "\n",
    "# Formatos:\n",
    "# Matriz:   (2, 3)\n",
    "# Escalar:  () -> é \"esticado\" para o formato (2, 3)\n",
    "resultado_escalar = matriz_base + escalar\n",
    "\n",
    "print(\"--- Broadcasting de Escalar ---\")\n",
    "print(\"Matriz (2, 3):\\n\", matriz_base)\n",
    "print(\"\\nEscalar:\", escalar)\n",
    "print(\"\\nResultado (Matriz + Escalar):\\n\", resultado_escalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081eebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 1: Somando um vetor-linha a uma matriz\n",
    "matriz = torch.ones((3, 4)) # Matriz 3x4\n",
    "vetor_linha = torch.arange(4, dtype=torch.float32) # Vetor 1x4\n",
    "\n",
    "# Formatos:\n",
    "# Matriz:      (3, 4)\n",
    "# Vetor-linha:    (4,) -> alinhado como (1, 4)\n",
    "# O vetor é \"esticado\" para o formato (3, 4) e somado a cada linha\n",
    "resultado = matriz + vetor_linha\n",
    "\n",
    "print(\"--- Broadcasting de Vetor-Linha ---\")\n",
    "print(\"Matriz (3, 4):\\n\", matriz)\n",
    "print(\"\\nVetor-linha (4,):\\n\", vetor_linha)\n",
    "print(\"\\nResultado (Matriz + Vetor-linha):\\n\", resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52677db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo 2: Somando um vetor-coluna a uma matriz\n",
    "vetor_coluna = torch.arange(3, dtype=torch.float32).reshape(3, 1) # Vetor 3x1\n",
    "\n",
    "# Formatos:\n",
    "# Matriz:       (3, 4)\n",
    "# Vetor-coluna: (3, 1)\n",
    "# O vetor-coluna é \"esticado\" nas colunas para o formato (3, 4)\n",
    "resultado_col = matriz + vetor_coluna\n",
    "\n",
    "print(\"--- Broadcasting de Vetor-Coluna ---\")\n",
    "print(\"Matriz (3, 4):\\n\", matriz)\n",
    "print(\"\\nVetor-coluna (3, 1):\\n\", vetor_coluna)\n",
    "print(\"\\nResultado (Matriz + Vetor-coluna):\\n\", resultado_col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
